{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2772fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "from ipynb.fs.full.Cert_Aux_Functions2 import *\n",
    "\n",
    "# Importa a biblioteca pandas \n",
    "import pandas as pd\n",
    "\n",
    "# Importa datetime e timedelta para verificar se há gaps de tempo nos datasets preparados\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Importa a biblioteca os\n",
    "import os\n",
    "\n",
    "## Bibliotecas sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# One Class SVM\n",
    "# https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Para as figuras\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "#Importa bibliotecas Numpy\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36109b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logon + HTTP + USB + Device\n",
    "df_lhud_1hora = pd.read_pickle(\"df_lhud_1hora_file.pkl\")\n",
    "df_lhud_1hora.sort_values('date', ascending=True, inplace = True)\n",
    "df_lhud_1hora.reset_index(inplace = True, drop=True)\n",
    "\n",
    "## Separa 4 primeiros meses de dados\n",
    "df_lhud_1hora4m = df_lhud_1hora[(df_lhud_1hora['date'] <= '2010-05-02')]\n",
    "\n",
    "train_index = df_lhud_1hora4m.index[-1]\n",
    "test_index = df_lhud_1hora[(df_lhud_1hora['date'] <= '2010-09-02')].index[-1]\n",
    "\n",
    "\n",
    "## Conjunto de teste\n",
    "df_lhud_1hora_test = df_lhud_1hora.iloc[train_index:test_index]\n",
    "\n",
    "### Transformações\n",
    "\n",
    "#Nomes das features numericas de acordo com o dataset\n",
    "lhud_numeric_features = ['logon', 'logoff','down','up','vis',\n",
    "                     'conn','disc','trm','frm','open',\n",
    "                     'write','copy','delete']\n",
    "\n",
    "#Nomes das features categoricas - comum a todos os datasets\n",
    "\n",
    "#numeric_transformer = StandardScaler()\n",
    "numeric_transformer = MinMaxScaler()\n",
    "#numeric_transformer = SimpleImputer()\n",
    "\n",
    "hour_categories = np.arange(0, 24)\n",
    "dow_categories  = np.arange(0, 7)\n",
    "user_categories = df_lhud_1hora4m.user.unique()\n",
    "\n",
    "#categorical_features = ['user','hour', 'dow']\n",
    "categorical_features = ['hour', 'dow']\n",
    "categorical_transformer = OneHotEncoder(\n",
    "#    categories = [user_categories, hour_categories, dow_categories]\n",
    "    categories = [hour_categories, dow_categories]\n",
    ")\n",
    "\n",
    "user_feature = ['user']\n",
    "#user_transformer = OrdinalEncoder(categories = [user_categories])\n",
    "user_transformer = OneHotEncoder(categories = [user_categories])\n",
    "                        \n",
    "lhud_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('lhud_num', numeric_transformer, lhud_numeric_features),\n",
    "        ('lhud_cat', categorical_transformer, categorical_features),\n",
    "        ('lhud_user', user_transformer, user_feature),\n",
    "    ])\n",
    "\n",
    "#Transformaçoes\n",
    "columns = lhud_numeric_features + categorical_features + user_feature\n",
    "trans_lhud_4m    = lhud_preprocessor.fit_transform(df_lhud_1hora4m[columns])\n",
    "trans_lhud_test  = lhud_preprocessor.transform(df_lhud_1hora_test[columns])\n",
    "trans_lhud       = lhud_preprocessor.transform(df_lhud_1hora[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Carrega Labels preditos do Snorkel\n",
    "labels_g_pd = pd.read_hdf(\"labels_g_pd.hdf\",'df')\n",
    "labels_g_pd['anom'] = np.where((labels_g_pd[0]== 1),-1,1)\n",
    "labels_g_pd[labels_g_pd['anom'] == -1].shape, labels_g_pd[labels_g_pd['anom'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2375bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "\n",
    "    clf_SGDOC=linear_model.SGDOneClassSVM(\n",
    "        nu=space['nu_s'], fit_intercept=space['fiti_s'], max_iter=space['maxi_s'], \n",
    "        tol=space['to_s'], #eta0=0.0,\n",
    "        learning_rate=space['lr_s']\n",
    "    )\n",
    "\n",
    "\n",
    "    clf_SGDOC.fit(trans_lhud_4m)\n",
    "\n",
    "    pred1 = clf_SGDOC.predict(trans_lhud_test)\n",
    "    dec1 = clf_SGDOC.decision_function(trans_lhud_test)\n",
    "    \n",
    "    anomalyScoresSGDOC = df_lhud_1hora_test\n",
    "    anomalyScoresSGDOC['scores']=dec1\n",
    "    anomalyScoresSGDOC['anom']=pred1\n",
    "    \n",
    "    a,p,r,f,cm,auc_sc = benchmark_snorkel(labels_g_pd,anomalyScoresSGDOC)\n",
    "    \n",
    "    global index\n",
    "    scores_df.loc[index,:]=np.array([index,space,a,p,r,f,auc_sc,np.reshape(cm,(4))],dtype=object)\n",
    "    \n",
    "    index=index+1\n",
    "    \n",
    "    print(space,r)\n",
    "    \n",
    "    return {'loss': -r, 'status': STATUS_OK, 'space': space,\n",
    "            'model': clf_SGDOC, 'f1_score': f,'auc_sc': auc_sc,\n",
    "           'precision': p, 'recall': r, 'c_matrix': cm}\n",
    "\n",
    "space ={'nu_s': hp.choice('nu_s', [0.01]),\n",
    "        'fiti_s': hp.choice('fiti_s', [True]),\n",
    "        'maxi_s': hp.choice('maxi_s', np.arange(10000,100000,10000)),\n",
    "        'to_s': hp.choice('to_s', [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]),\n",
    "        'lr_s' : hp.choice('lr_s', [\"optimal\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3343ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(columns=[\"Model\",\"Params\",\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\",\"ROC-AUC\", \"CM\"])\n",
    "index=0\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Melhor modelo pelas metricas Recall e ROC-AUC\n",
    "scores_df.sort_values(['Recall','ROC-AUC'], ascending=[False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c587334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c55cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cert",
   "language": "python",
   "name": "cert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
